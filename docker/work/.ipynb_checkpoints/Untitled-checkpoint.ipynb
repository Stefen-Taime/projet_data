{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d209569-ad86-4825-88da-7b44b874b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apache spark application processing logic [elt]\n",
    "# [input] = data lake\n",
    "# [transformation] = business logic using pyspark and spark sql\n",
    "# [output] = data warehouse\n",
    "\n",
    "# import libraries\n",
    "from os.path import abspath\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# set default location for warehouse\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "\n",
    "# main spark program\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # init session\n",
    "    spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"etl-yelp-py\") \\\n",
    "            .config(\"spark.sql.warehouse.dir\", abspath('spark-warehouse')) \\\n",
    "            .enableHiveSupport() \\\n",
    "            .getOrCreate()\n",
    "\n",
    "    # show configured parameters\n",
    "    print(SparkConf().getAll())\n",
    "\n",
    "    # set log level\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "    # set dynamic input file [hard-coded]\n",
    "    # can be changed for input parameters [spark-submit]\n",
    "    get_users_file = \"/home/stefen/work/landing-zone/user/*.json\"\n",
    "    get_business_file = \"/home/stefen/work/landing-zone/business/*.json\"\n",
    "    get_reviews_file = \"/home/stefen/work/landing-zone/review/*.json\"\n",
    "\n",
    "    # read user data\n",
    "    df_user = spark.read \\\n",
    "        .format(\"json\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .json(get_users_file)\n",
    "\n",
    "    # read business data\n",
    "    df_business = spark.read \\\n",
    "        .format(\"json\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .json(get_business_file)\n",
    "\n",
    "    # read review data\n",
    "    df_review = spark.read \\\n",
    "        .format(\"json\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .json(get_reviews_file)\n",
    "\n",
    "    # get number of partitions\n",
    "    # [25], [16], [48]\n",
    "    print(df_user.rdd.getNumPartitions())\n",
    "    print(df_business.rdd.getNumPartitions())\n",
    "    print(df_review.rdd.getNumPartitions())\n",
    "\n",
    "    # print schema of dataframe\n",
    "    df_user.printSchema()\n",
    "    df_business.printSchema()\n",
    "    df_review.printSchema()\n",
    "\n",
    "    # display data\n",
    "    df_user.show()\n",
    "    df_business.show()\n",
    "    df_review.show()\n",
    "\n",
    "    # count rows\n",
    "    df_user.count()\n",
    "    df_business.count()\n",
    "    df_review.count()\n",
    "\n",
    "    # resides on [pyspark] engine\n",
    "    # register df into sql engine\n",
    "    df_business.createOrReplaceTempView(\"business\")\n",
    "    df_user.createOrReplaceTempView(\"user\")\n",
    "    df_review.createOrReplaceTempView(\"review\")\n",
    "\n",
    "    # sql join into a new [df]\n",
    "    df_join = spark.sql(\"\"\"\n",
    "        SELECT u.user_id,\n",
    "               u.name AS user,\n",
    "               u.average_stars AS user_avg_stars,\n",
    "               u.useful AS user_useful, \n",
    "               u.review_count AS user_review_count,\n",
    "               u.yelping_since,\n",
    "               b.business_id,\n",
    "               b.name AS business,\n",
    "               b.city,\n",
    "               b.state,\n",
    "               b.stars AS business_stars,\n",
    "               b.review_count AS business_review_count,\n",
    "               r.useful AS review_useful,\n",
    "               r.stars AS review_stars,\n",
    "               r.date AS date\n",
    "        FROM review AS r\n",
    "        INNER JOIN business AS b\n",
    "        ON r.business_id = b.business_id\n",
    "        INNER JOIN user AS u\n",
    "        ON u.user_id = r.user_id\n",
    "    \"\"\")\n",
    "\n",
    "    # show & count df\n",
    "    df_join.explain()\n",
    "    df_join.count()\n",
    "\n",
    "    # show df\n",
    "    df_join.show()\n",
    "\n",
    "    # stop session\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
